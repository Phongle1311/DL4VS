{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DEEP LEARNING FOR COMPUTER SYSTEM**\n",
        "# **Chapter 4: Project Structuring and Hyperparameter tuning**\n",
        "\n",
        "\n",
        "## **Improve Images classification with CNN on CIFAR-10 dataset**\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "WsoepNOfaGWm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Get the data ready for training"
      ],
      "metadata": {
        "id": "I5DyspwPaXt-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVZYEafsaCoU",
        "outputId": "6aacf2a7-a05e-4052-e649-ca934d9f5613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n"
          ]
        }
      ],
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "# load dataset\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "metadata": {
        "id": "Z8CTgrEGbmQx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split train-val\n",
        "(X_train, X_val) = X_train[5000:], X_train[:5000]\n",
        "(y_train, y_val) = y_train[5000:], y_train[:5000]\n",
        "\n",
        "print('X_train shape: ', X_train.shape)\n",
        "print('X_val shape: ', X_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQbnWgUMb4KG",
        "outputId": "d6a0e141-cd98-4636-9189-cd834b175d95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (45000, 32, 32, 3)\n",
            "X_val shape:  (5000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: only normalize val and test set with mean and std caculated from train set."
      ],
      "metadata": {
        "id": "30zv6ZJ5dLHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize input\n",
        "import numpy as np\n",
        "\n",
        "mean = np.mean(X_train, axis=(0,1,2,3))\n",
        "std = np.std(X_train, axis=(0,1,2,3))\n",
        "epsilon = 1e-7\n",
        "\n",
        "X_train = (X_train - mean)/(std+epsilon)\n",
        "X_val = (X_val - mean)/(std+epsilon)\n",
        "X_test = (X_test - mean)/(std+epsilon)"
      ],
      "metadata": {
        "id": "3pxxQncWcSyR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode categorical label using one-hot\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "y_train = to_categorical(y_train, n_classes)\n",
        "y_val = to_categorical(y_val, n_classes)\n",
        "y_test = to_categorical(y_test, n_classes)"
      ],
      "metadata": {
        "id": "ZWlp7yyodTwO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "UqX60qsxd3f0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Build the Model's Architecture"
      ],
      "metadata": {
        "id": "MrcyQKEee7Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout,\\\n",
        "  BatchNormalization\n",
        "from keras import regularizers, optimizers\n",
        "\n",
        "base_hidden_units = 32\n",
        "w_decay = 1e-4\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# CONV1\n",
        "model.add(Conv2D(filters=base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(w_decay),\n",
        "                 activation='relu', input_shape=X_train.shape[1:]))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV2\n",
        "model.add(Conv2D(filters=base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(w_decay),\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL+Dropout\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "# CONV3\n",
        "model.add(Conv2D(filters=2*base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(w_decay),\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV4\n",
        "model.add(Conv2D(filters=2*base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(w_decay),\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL+Dropout\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# CONV5\n",
        "model.add(Conv2D(filters=4*base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(w_decay),\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# CONV6\n",
        "model.add(Conv2D(filters=4*base_hidden_units, kernel_size=3, padding='same',\n",
        "                 kernel_regularizer=regularizers.l2(w_decay),\n",
        "                 activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "# POOL+Dropout\n",
        "model.add(MaxPooling2D())\n",
        "model.add(Dropout(0.4))\n",
        "\n",
        "# FC7\n",
        "model.add(Flatten())\n",
        "model.add(Dense(n_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuWDf-11ewio",
        "outputId": "4823b0f7-9fca-47d2-c871-d70060822924"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 32, 32, 32)        128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 32, 32, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 16, 16, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 16, 16, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 64)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 8, 8, 64)          0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 8, 8, 128)         512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 128)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 309290 (1.18 MB)\n",
            "Trainable params: 308394 (1.18 MB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Non-trainable params means the number of weights that are not updated during training with backpropagation.*\n",
        "\n",
        "There are mainly two types of non-trainable weights:\n",
        "\n",
        "- The ones that you have chosen to keep constant when training. This means that keras won't update these weights during training at all.\n",
        "- The ones that work like statistics in BatchNormalization layers. They're updated with mean and variance, but they're not \"trained with backpropagation\"\n",
        "\n",
        "params # of BN layer = 4 * depth\n",
        "Non-trainable params = 2 * depth"
      ],
      "metadata": {
        "id": "soMwXPf_n9Uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Train the model"
      ],
      "metadata": {
        "id": "RP2vbBXSjdyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "epochs = 125"
      ],
      "metadata": {
        "id": "sofPz7aSjMOM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5',\n",
        "                                    verbose=1, save_best_only=True)\n",
        "\n",
        "optimizer = optimizers.RMSprop(learning_rate=0.0001, weight_decay=1e-6)"
      ],
      "metadata": {
        "id": "ILZTjhk_p8cb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "f81YomzUqdGn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(datagen.flow(X_train, y_train, batch_size),\n",
        "                           callbacks=[checkpointer], epochs = epochs, verbose=2,\n",
        "                           steps_per_epoch=len(X_train)//batch_size,\n",
        "                           validation_data=(X_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgXoJhjMsrgN",
        "outputId": "37b6d0d2-41bd-458b-8253-7f90d3218f45"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/125\n",
            "\n",
            "Epoch 1: val_loss improved from inf to 1.61407, saving model to model.weights.best.hdf5\n",
            "703/703 - 40s - loss: 2.5965 - accuracy: 0.2966 - val_loss: 1.6141 - val_accuracy: 0.4500 - 40s/epoch - 57ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/125\n",
            "\n",
            "Epoch 2: val_loss improved from 1.61407 to 1.44235, saving model to model.weights.best.hdf5\n",
            "703/703 - 33s - loss: 1.9314 - accuracy: 0.3923 - val_loss: 1.4424 - val_accuracy: 0.5062 - 33s/epoch - 47ms/step\n",
            "Epoch 3/125\n",
            "\n",
            "Epoch 3: val_loss improved from 1.44235 to 1.41475, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 1.7035 - accuracy: 0.4507 - val_loss: 1.4148 - val_accuracy: 0.5302 - 31s/epoch - 44ms/step\n",
            "Epoch 4/125\n",
            "\n",
            "Epoch 4: val_loss improved from 1.41475 to 1.29435, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 1.5467 - accuracy: 0.4948 - val_loss: 1.2943 - val_accuracy: 0.5696 - 31s/epoch - 44ms/step\n",
            "Epoch 5/125\n",
            "\n",
            "Epoch 5: val_loss did not improve from 1.29435\n",
            "703/703 - 29s - loss: 1.4450 - accuracy: 0.5242 - val_loss: 1.3070 - val_accuracy: 0.5664 - 29s/epoch - 42ms/step\n",
            "Epoch 6/125\n",
            "\n",
            "Epoch 6: val_loss improved from 1.29435 to 1.19562, saving model to model.weights.best.hdf5\n",
            "703/703 - 32s - loss: 1.3466 - accuracy: 0.5535 - val_loss: 1.1956 - val_accuracy: 0.6056 - 32s/epoch - 45ms/step\n",
            "Epoch 7/125\n",
            "\n",
            "Epoch 7: val_loss improved from 1.19562 to 1.09230, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 1.2695 - accuracy: 0.5780 - val_loss: 1.0923 - val_accuracy: 0.6370 - 31s/epoch - 44ms/step\n",
            "Epoch 8/125\n",
            "\n",
            "Epoch 8: val_loss did not improve from 1.09230\n",
            "703/703 - 31s - loss: 1.2059 - accuracy: 0.5969 - val_loss: 1.0963 - val_accuracy: 0.6382 - 31s/epoch - 44ms/step\n",
            "Epoch 9/125\n",
            "\n",
            "Epoch 9: val_loss improved from 1.09230 to 1.05043, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 1.1468 - accuracy: 0.6166 - val_loss: 1.0504 - val_accuracy: 0.6598 - 31s/epoch - 44ms/step\n",
            "Epoch 10/125\n",
            "\n",
            "Epoch 10: val_loss improved from 1.05043 to 1.03409, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 1.0987 - accuracy: 0.6346 - val_loss: 1.0341 - val_accuracy: 0.6632 - 30s/epoch - 43ms/step\n",
            "Epoch 11/125\n",
            "\n",
            "Epoch 11: val_loss improved from 1.03409 to 0.91410, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 1.0658 - accuracy: 0.6463 - val_loss: 0.9141 - val_accuracy: 0.7064 - 31s/epoch - 44ms/step\n",
            "Epoch 12/125\n",
            "\n",
            "Epoch 12: val_loss did not improve from 0.91410\n",
            "703/703 - 30s - loss: 1.0267 - accuracy: 0.6545 - val_loss: 0.9469 - val_accuracy: 0.6974 - 30s/epoch - 43ms/step\n",
            "Epoch 13/125\n",
            "\n",
            "Epoch 13: val_loss did not improve from 0.91410\n",
            "703/703 - 31s - loss: 0.9858 - accuracy: 0.6702 - val_loss: 0.9269 - val_accuracy: 0.7006 - 31s/epoch - 44ms/step\n",
            "Epoch 14/125\n",
            "\n",
            "Epoch 14: val_loss improved from 0.91410 to 0.88592, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.9644 - accuracy: 0.6796 - val_loss: 0.8859 - val_accuracy: 0.7092 - 30s/epoch - 42ms/step\n",
            "Epoch 15/125\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.88592\n",
            "703/703 - 31s - loss: 0.9460 - accuracy: 0.6850 - val_loss: 0.8950 - val_accuracy: 0.7140 - 31s/epoch - 44ms/step\n",
            "Epoch 16/125\n",
            "\n",
            "Epoch 16: val_loss improved from 0.88592 to 0.84958, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.9168 - accuracy: 0.6928 - val_loss: 0.8496 - val_accuracy: 0.7264 - 31s/epoch - 45ms/step\n",
            "Epoch 17/125\n",
            "\n",
            "Epoch 17: val_loss improved from 0.84958 to 0.81605, saving model to model.weights.best.hdf5\n",
            "703/703 - 32s - loss: 0.8886 - accuracy: 0.7031 - val_loss: 0.8160 - val_accuracy: 0.7368 - 32s/epoch - 46ms/step\n",
            "Epoch 18/125\n",
            "\n",
            "Epoch 18: val_loss improved from 0.81605 to 0.80331, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.8778 - accuracy: 0.7067 - val_loss: 0.8033 - val_accuracy: 0.7424 - 30s/epoch - 42ms/step\n",
            "Epoch 19/125\n",
            "\n",
            "Epoch 19: val_loss improved from 0.80331 to 0.77455, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.8553 - accuracy: 0.7149 - val_loss: 0.7746 - val_accuracy: 0.7540 - 31s/epoch - 44ms/step\n",
            "Epoch 20/125\n",
            "\n",
            "Epoch 20: val_loss did not improve from 0.77455\n",
            "703/703 - 29s - loss: 0.8363 - accuracy: 0.7219 - val_loss: 0.8037 - val_accuracy: 0.7474 - 29s/epoch - 41ms/step\n",
            "Epoch 21/125\n",
            "\n",
            "Epoch 21: val_loss did not improve from 0.77455\n",
            "703/703 - 31s - loss: 0.8273 - accuracy: 0.7257 - val_loss: 0.8098 - val_accuracy: 0.7454 - 31s/epoch - 44ms/step\n",
            "Epoch 22/125\n",
            "\n",
            "Epoch 22: val_loss did not improve from 0.77455\n",
            "703/703 - 32s - loss: 0.8080 - accuracy: 0.7319 - val_loss: 0.7913 - val_accuracy: 0.7544 - 32s/epoch - 45ms/step\n",
            "Epoch 23/125\n",
            "\n",
            "Epoch 23: val_loss improved from 0.77455 to 0.72506, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.7979 - accuracy: 0.7357 - val_loss: 0.7251 - val_accuracy: 0.7664 - 30s/epoch - 43ms/step\n",
            "Epoch 24/125\n",
            "\n",
            "Epoch 24: val_loss improved from 0.72506 to 0.71093, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.7810 - accuracy: 0.7411 - val_loss: 0.7109 - val_accuracy: 0.7726 - 31s/epoch - 45ms/step\n",
            "Epoch 25/125\n",
            "\n",
            "Epoch 25: val_loss did not improve from 0.71093\n",
            "703/703 - 30s - loss: 0.7798 - accuracy: 0.7405 - val_loss: 0.7408 - val_accuracy: 0.7684 - 30s/epoch - 43ms/step\n",
            "Epoch 26/125\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.71093\n",
            "703/703 - 31s - loss: 0.7699 - accuracy: 0.7437 - val_loss: 0.7290 - val_accuracy: 0.7660 - 31s/epoch - 44ms/step\n",
            "Epoch 27/125\n",
            "\n",
            "Epoch 27: val_loss improved from 0.71093 to 0.68755, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.7530 - accuracy: 0.7519 - val_loss: 0.6875 - val_accuracy: 0.7866 - 30s/epoch - 43ms/step\n",
            "Epoch 28/125\n",
            "\n",
            "Epoch 28: val_loss did not improve from 0.68755\n",
            "703/703 - 32s - loss: 0.7405 - accuracy: 0.7565 - val_loss: 0.6914 - val_accuracy: 0.7802 - 32s/epoch - 46ms/step\n",
            "Epoch 29/125\n",
            "\n",
            "Epoch 29: val_loss did not improve from 0.68755\n",
            "703/703 - 30s - loss: 0.7277 - accuracy: 0.7600 - val_loss: 0.7238 - val_accuracy: 0.7728 - 30s/epoch - 43ms/step\n",
            "Epoch 30/125\n",
            "\n",
            "Epoch 30: val_loss improved from 0.68755 to 0.68638, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.7192 - accuracy: 0.7619 - val_loss: 0.6864 - val_accuracy: 0.7910 - 31s/epoch - 44ms/step\n",
            "Epoch 31/125\n",
            "\n",
            "Epoch 31: val_loss improved from 0.68638 to 0.62867, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.7199 - accuracy: 0.7633 - val_loss: 0.6287 - val_accuracy: 0.8032 - 30s/epoch - 43ms/step\n",
            "Epoch 32/125\n",
            "\n",
            "Epoch 32: val_loss did not improve from 0.62867\n",
            "703/703 - 31s - loss: 0.7053 - accuracy: 0.7674 - val_loss: 0.6592 - val_accuracy: 0.7910 - 31s/epoch - 44ms/step\n",
            "Epoch 33/125\n",
            "\n",
            "Epoch 33: val_loss did not improve from 0.62867\n",
            "703/703 - 31s - loss: 0.7019 - accuracy: 0.7683 - val_loss: 0.6646 - val_accuracy: 0.7948 - 31s/epoch - 43ms/step\n",
            "Epoch 34/125\n",
            "\n",
            "Epoch 34: val_loss did not improve from 0.62867\n",
            "703/703 - 31s - loss: 0.6923 - accuracy: 0.7713 - val_loss: 0.6415 - val_accuracy: 0.8010 - 31s/epoch - 43ms/step\n",
            "Epoch 35/125\n",
            "\n",
            "Epoch 35: val_loss did not improve from 0.62867\n",
            "703/703 - 32s - loss: 0.6804 - accuracy: 0.7774 - val_loss: 0.6464 - val_accuracy: 0.7960 - 32s/epoch - 46ms/step\n",
            "Epoch 36/125\n",
            "\n",
            "Epoch 36: val_loss did not improve from 0.62867\n",
            "703/703 - 32s - loss: 0.6738 - accuracy: 0.7763 - val_loss: 0.6321 - val_accuracy: 0.8030 - 32s/epoch - 45ms/step\n",
            "Epoch 37/125\n",
            "\n",
            "Epoch 37: val_loss did not improve from 0.62867\n",
            "703/703 - 31s - loss: 0.6728 - accuracy: 0.7801 - val_loss: 0.6377 - val_accuracy: 0.8002 - 31s/epoch - 44ms/step\n",
            "Epoch 38/125\n",
            "\n",
            "Epoch 38: val_loss improved from 0.62867 to 0.59204, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.6644 - accuracy: 0.7828 - val_loss: 0.5920 - val_accuracy: 0.8196 - 31s/epoch - 44ms/step\n",
            "Epoch 39/125\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.59204\n",
            "703/703 - 31s - loss: 0.6594 - accuracy: 0.7832 - val_loss: 0.6409 - val_accuracy: 0.8034 - 31s/epoch - 43ms/step\n",
            "Epoch 40/125\n",
            "\n",
            "Epoch 40: val_loss did not improve from 0.59204\n",
            "703/703 - 31s - loss: 0.6494 - accuracy: 0.7862 - val_loss: 0.6397 - val_accuracy: 0.8004 - 31s/epoch - 44ms/step\n",
            "Epoch 41/125\n",
            "\n",
            "Epoch 41: val_loss improved from 0.59204 to 0.57677, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.6479 - accuracy: 0.7869 - val_loss: 0.5768 - val_accuracy: 0.8200 - 31s/epoch - 44ms/step\n",
            "Epoch 42/125\n",
            "\n",
            "Epoch 42: val_loss did not improve from 0.57677\n",
            "703/703 - 31s - loss: 0.6403 - accuracy: 0.7922 - val_loss: 0.5975 - val_accuracy: 0.8154 - 31s/epoch - 45ms/step\n",
            "Epoch 43/125\n",
            "\n",
            "Epoch 43: val_loss improved from 0.57677 to 0.57616, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.6365 - accuracy: 0.7906 - val_loss: 0.5762 - val_accuracy: 0.8256 - 31s/epoch - 44ms/step\n",
            "Epoch 44/125\n",
            "\n",
            "Epoch 44: val_loss did not improve from 0.57616\n",
            "703/703 - 32s - loss: 0.6213 - accuracy: 0.7968 - val_loss: 0.5900 - val_accuracy: 0.8166 - 32s/epoch - 45ms/step\n",
            "Epoch 45/125\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.57616\n",
            "703/703 - 34s - loss: 0.6212 - accuracy: 0.7969 - val_loss: 0.6239 - val_accuracy: 0.8112 - 34s/epoch - 49ms/step\n",
            "Epoch 46/125\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.57616\n",
            "703/703 - 31s - loss: 0.6228 - accuracy: 0.7968 - val_loss: 0.5833 - val_accuracy: 0.8236 - 31s/epoch - 44ms/step\n",
            "Epoch 47/125\n",
            "\n",
            "Epoch 47: val_loss did not improve from 0.57616\n",
            "703/703 - 31s - loss: 0.6112 - accuracy: 0.8012 - val_loss: 0.5895 - val_accuracy: 0.8204 - 31s/epoch - 44ms/step\n",
            "Epoch 48/125\n",
            "\n",
            "Epoch 48: val_loss did not improve from 0.57616\n",
            "703/703 - 30s - loss: 0.6104 - accuracy: 0.8009 - val_loss: 0.5994 - val_accuracy: 0.8178 - 30s/epoch - 43ms/step\n",
            "Epoch 49/125\n",
            "\n",
            "Epoch 49: val_loss did not improve from 0.57616\n",
            "703/703 - 32s - loss: 0.6003 - accuracy: 0.8047 - val_loss: 0.6020 - val_accuracy: 0.8140 - 32s/epoch - 46ms/step\n",
            "Epoch 50/125\n",
            "\n",
            "Epoch 50: val_loss improved from 0.57616 to 0.56547, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.6020 - accuracy: 0.8051 - val_loss: 0.5655 - val_accuracy: 0.8268 - 30s/epoch - 43ms/step\n",
            "Epoch 51/125\n",
            "\n",
            "Epoch 51: val_loss improved from 0.56547 to 0.54510, saving model to model.weights.best.hdf5\n",
            "703/703 - 31s - loss: 0.5993 - accuracy: 0.8049 - val_loss: 0.5451 - val_accuracy: 0.8344 - 31s/epoch - 44ms/step\n",
            "Epoch 52/125\n",
            "\n",
            "Epoch 52: val_loss did not improve from 0.54510\n",
            "703/703 - 30s - loss: 0.5939 - accuracy: 0.8067 - val_loss: 0.5609 - val_accuracy: 0.8302 - 30s/epoch - 43ms/step\n",
            "Epoch 53/125\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.54510\n",
            "703/703 - 31s - loss: 0.5869 - accuracy: 0.8109 - val_loss: 0.5628 - val_accuracy: 0.8266 - 31s/epoch - 44ms/step\n",
            "Epoch 54/125\n",
            "\n",
            "Epoch 54: val_loss did not improve from 0.54510\n",
            "703/703 - 31s - loss: 0.5827 - accuracy: 0.8116 - val_loss: 0.5661 - val_accuracy: 0.8284 - 31s/epoch - 44ms/step\n",
            "Epoch 55/125\n",
            "\n",
            "Epoch 55: val_loss improved from 0.54510 to 0.54458, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.5812 - accuracy: 0.8128 - val_loss: 0.5446 - val_accuracy: 0.8350 - 30s/epoch - 43ms/step\n",
            "Epoch 56/125\n",
            "\n",
            "Epoch 56: val_loss improved from 0.54458 to 0.53006, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.5802 - accuracy: 0.8128 - val_loss: 0.5301 - val_accuracy: 0.8388 - 29s/epoch - 41ms/step\n",
            "Epoch 57/125\n",
            "\n",
            "Epoch 57: val_loss did not improve from 0.53006\n",
            "703/703 - 30s - loss: 0.5687 - accuracy: 0.8168 - val_loss: 0.5500 - val_accuracy: 0.8336 - 30s/epoch - 43ms/step\n",
            "Epoch 58/125\n",
            "\n",
            "Epoch 58: val_loss did not improve from 0.53006\n",
            "703/703 - 30s - loss: 0.5685 - accuracy: 0.8162 - val_loss: 0.5420 - val_accuracy: 0.8310 - 30s/epoch - 43ms/step\n",
            "Epoch 59/125\n",
            "\n",
            "Epoch 59: val_loss did not improve from 0.53006\n",
            "703/703 - 30s - loss: 0.5617 - accuracy: 0.8158 - val_loss: 0.5306 - val_accuracy: 0.8388 - 30s/epoch - 43ms/step\n",
            "Epoch 60/125\n",
            "\n",
            "Epoch 60: val_loss improved from 0.53006 to 0.51471, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.5578 - accuracy: 0.8184 - val_loss: 0.5147 - val_accuracy: 0.8452 - 30s/epoch - 42ms/step\n",
            "Epoch 61/125\n",
            "\n",
            "Epoch 61: val_loss did not improve from 0.51471\n",
            "703/703 - 30s - loss: 0.5646 - accuracy: 0.8183 - val_loss: 0.5439 - val_accuracy: 0.8318 - 30s/epoch - 42ms/step\n",
            "Epoch 62/125\n",
            "\n",
            "Epoch 62: val_loss did not improve from 0.51471\n",
            "703/703 - 30s - loss: 0.5600 - accuracy: 0.8201 - val_loss: 0.5498 - val_accuracy: 0.8346 - 30s/epoch - 42ms/step\n",
            "Epoch 63/125\n",
            "\n",
            "Epoch 63: val_loss did not improve from 0.51471\n",
            "703/703 - 30s - loss: 0.5509 - accuracy: 0.8199 - val_loss: 0.5288 - val_accuracy: 0.8408 - 30s/epoch - 43ms/step\n",
            "Epoch 64/125\n",
            "\n",
            "Epoch 64: val_loss improved from 0.51471 to 0.49973, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.5495 - accuracy: 0.8231 - val_loss: 0.4997 - val_accuracy: 0.8458 - 29s/epoch - 41ms/step\n",
            "Epoch 65/125\n",
            "\n",
            "Epoch 65: val_loss did not improve from 0.49973\n",
            "703/703 - 30s - loss: 0.5446 - accuracy: 0.8244 - val_loss: 0.5360 - val_accuracy: 0.8362 - 30s/epoch - 42ms/step\n",
            "Epoch 66/125\n",
            "\n",
            "Epoch 66: val_loss did not improve from 0.49973\n",
            "703/703 - 30s - loss: 0.5384 - accuracy: 0.8270 - val_loss: 0.5385 - val_accuracy: 0.8390 - 30s/epoch - 43ms/step\n",
            "Epoch 67/125\n",
            "\n",
            "Epoch 67: val_loss did not improve from 0.49973\n",
            "703/703 - 30s - loss: 0.5375 - accuracy: 0.8274 - val_loss: 0.5112 - val_accuracy: 0.8450 - 30s/epoch - 43ms/step\n",
            "Epoch 68/125\n",
            "\n",
            "Epoch 68: val_loss did not improve from 0.49973\n",
            "703/703 - 29s - loss: 0.5348 - accuracy: 0.8277 - val_loss: 0.5258 - val_accuracy: 0.8456 - 29s/epoch - 41ms/step\n",
            "Epoch 69/125\n",
            "\n",
            "Epoch 69: val_loss did not improve from 0.49973\n",
            "703/703 - 29s - loss: 0.5305 - accuracy: 0.8287 - val_loss: 0.5023 - val_accuracy: 0.8514 - 29s/epoch - 41ms/step\n",
            "Epoch 70/125\n",
            "\n",
            "Epoch 70: val_loss did not improve from 0.49973\n",
            "703/703 - 30s - loss: 0.5300 - accuracy: 0.8292 - val_loss: 0.5271 - val_accuracy: 0.8416 - 30s/epoch - 43ms/step\n",
            "Epoch 71/125\n",
            "\n",
            "Epoch 71: val_loss improved from 0.49973 to 0.49262, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.5307 - accuracy: 0.8293 - val_loss: 0.4926 - val_accuracy: 0.8524 - 29s/epoch - 41ms/step\n",
            "Epoch 72/125\n",
            "\n",
            "Epoch 72: val_loss did not improve from 0.49262\n",
            "703/703 - 30s - loss: 0.5285 - accuracy: 0.8306 - val_loss: 0.5202 - val_accuracy: 0.8402 - 30s/epoch - 42ms/step\n",
            "Epoch 73/125\n",
            "\n",
            "Epoch 73: val_loss did not improve from 0.49262\n",
            "703/703 - 29s - loss: 0.5211 - accuracy: 0.8311 - val_loss: 0.4988 - val_accuracy: 0.8512 - 29s/epoch - 41ms/step\n",
            "Epoch 74/125\n",
            "\n",
            "Epoch 74: val_loss improved from 0.49262 to 0.48641, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.5182 - accuracy: 0.8346 - val_loss: 0.4864 - val_accuracy: 0.8512 - 30s/epoch - 42ms/step\n",
            "Epoch 75/125\n",
            "\n",
            "Epoch 75: val_loss did not improve from 0.48641\n",
            "703/703 - 30s - loss: 0.5243 - accuracy: 0.8294 - val_loss: 0.4944 - val_accuracy: 0.8544 - 30s/epoch - 42ms/step\n",
            "Epoch 76/125\n",
            "\n",
            "Epoch 76: val_loss did not improve from 0.48641\n",
            "703/703 - 30s - loss: 0.5137 - accuracy: 0.8370 - val_loss: 0.5106 - val_accuracy: 0.8482 - 30s/epoch - 42ms/step\n",
            "Epoch 77/125\n",
            "\n",
            "Epoch 77: val_loss did not improve from 0.48641\n",
            "703/703 - 29s - loss: 0.5115 - accuracy: 0.8354 - val_loss: 0.5072 - val_accuracy: 0.8510 - 29s/epoch - 41ms/step\n",
            "Epoch 78/125\n",
            "\n",
            "Epoch 78: val_loss improved from 0.48641 to 0.47568, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.5118 - accuracy: 0.8355 - val_loss: 0.4757 - val_accuracy: 0.8550 - 30s/epoch - 42ms/step\n",
            "Epoch 79/125\n",
            "\n",
            "Epoch 79: val_loss did not improve from 0.47568\n",
            "703/703 - 29s - loss: 0.5112 - accuracy: 0.8397 - val_loss: 0.4787 - val_accuracy: 0.8572 - 29s/epoch - 41ms/step\n",
            "Epoch 80/125\n",
            "\n",
            "Epoch 80: val_loss did not improve from 0.47568\n",
            "703/703 - 30s - loss: 0.5088 - accuracy: 0.8385 - val_loss: 0.4895 - val_accuracy: 0.8520 - 30s/epoch - 42ms/step\n",
            "Epoch 81/125\n",
            "\n",
            "Epoch 81: val_loss did not improve from 0.47568\n",
            "703/703 - 29s - loss: 0.5100 - accuracy: 0.8363 - val_loss: 0.5015 - val_accuracy: 0.8502 - 29s/epoch - 41ms/step\n",
            "Epoch 82/125\n",
            "\n",
            "Epoch 82: val_loss did not improve from 0.47568\n",
            "703/703 - 29s - loss: 0.5047 - accuracy: 0.8402 - val_loss: 0.4874 - val_accuracy: 0.8606 - 29s/epoch - 41ms/step\n",
            "Epoch 83/125\n",
            "\n",
            "Epoch 83: val_loss did not improve from 0.47568\n",
            "703/703 - 29s - loss: 0.5003 - accuracy: 0.8415 - val_loss: 0.4770 - val_accuracy: 0.8576 - 29s/epoch - 42ms/step\n",
            "Epoch 84/125\n",
            "\n",
            "Epoch 84: val_loss improved from 0.47568 to 0.47389, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.4984 - accuracy: 0.8413 - val_loss: 0.4739 - val_accuracy: 0.8592 - 30s/epoch - 43ms/step\n",
            "Epoch 85/125\n",
            "\n",
            "Epoch 85: val_loss did not improve from 0.47389\n",
            "703/703 - 30s - loss: 0.4982 - accuracy: 0.8404 - val_loss: 0.4889 - val_accuracy: 0.8556 - 30s/epoch - 42ms/step\n",
            "Epoch 86/125\n",
            "\n",
            "Epoch 86: val_loss improved from 0.47389 to 0.44656, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.4974 - accuracy: 0.8391 - val_loss: 0.4466 - val_accuracy: 0.8664 - 29s/epoch - 41ms/step\n",
            "Epoch 87/125\n",
            "\n",
            "Epoch 87: val_loss did not improve from 0.44656\n",
            "703/703 - 30s - loss: 0.4873 - accuracy: 0.8443 - val_loss: 0.5123 - val_accuracy: 0.8502 - 30s/epoch - 43ms/step\n",
            "Epoch 88/125\n",
            "\n",
            "Epoch 88: val_loss did not improve from 0.44656\n",
            "703/703 - 30s - loss: 0.4963 - accuracy: 0.8417 - val_loss: 0.4601 - val_accuracy: 0.8620 - 30s/epoch - 43ms/step\n",
            "Epoch 89/125\n",
            "\n",
            "Epoch 89: val_loss did not improve from 0.44656\n",
            "703/703 - 30s - loss: 0.4900 - accuracy: 0.8444 - val_loss: 0.4761 - val_accuracy: 0.8564 - 30s/epoch - 42ms/step\n",
            "Epoch 90/125\n",
            "\n",
            "Epoch 90: val_loss did not improve from 0.44656\n",
            "703/703 - 29s - loss: 0.4820 - accuracy: 0.8469 - val_loss: 0.4755 - val_accuracy: 0.8566 - 29s/epoch - 41ms/step\n",
            "Epoch 91/125\n",
            "\n",
            "Epoch 91: val_loss did not improve from 0.44656\n",
            "703/703 - 30s - loss: 0.4796 - accuracy: 0.8464 - val_loss: 0.5130 - val_accuracy: 0.8520 - 30s/epoch - 42ms/step\n",
            "Epoch 92/125\n",
            "\n",
            "Epoch 92: val_loss did not improve from 0.44656\n",
            "703/703 - 29s - loss: 0.4786 - accuracy: 0.8482 - val_loss: 0.4511 - val_accuracy: 0.8652 - 29s/epoch - 41ms/step\n",
            "Epoch 93/125\n",
            "\n",
            "Epoch 93: val_loss did not improve from 0.44656\n",
            "703/703 - 30s - loss: 0.4834 - accuracy: 0.8458 - val_loss: 0.4606 - val_accuracy: 0.8630 - 30s/epoch - 43ms/step\n",
            "Epoch 94/125\n",
            "\n",
            "Epoch 94: val_loss did not improve from 0.44656\n",
            "703/703 - 29s - loss: 0.4772 - accuracy: 0.8482 - val_loss: 0.4509 - val_accuracy: 0.8646 - 29s/epoch - 41ms/step\n",
            "Epoch 95/125\n",
            "\n",
            "Epoch 95: val_loss did not improve from 0.44656\n",
            "703/703 - 29s - loss: 0.4732 - accuracy: 0.8485 - val_loss: 0.4667 - val_accuracy: 0.8610 - 29s/epoch - 41ms/step\n",
            "Epoch 96/125\n",
            "\n",
            "Epoch 96: val_loss did not improve from 0.44656\n",
            "703/703 - 30s - loss: 0.4713 - accuracy: 0.8509 - val_loss: 0.4749 - val_accuracy: 0.8628 - 30s/epoch - 42ms/step\n",
            "Epoch 97/125\n",
            "\n",
            "Epoch 97: val_loss did not improve from 0.44656\n",
            "703/703 - 29s - loss: 0.4742 - accuracy: 0.8474 - val_loss: 0.4875 - val_accuracy: 0.8594 - 29s/epoch - 41ms/step\n",
            "Epoch 98/125\n",
            "\n",
            "Epoch 98: val_loss did not improve from 0.44656\n",
            "703/703 - 31s - loss: 0.4732 - accuracy: 0.8509 - val_loss: 0.4768 - val_accuracy: 0.8616 - 31s/epoch - 43ms/step\n",
            "Epoch 99/125\n",
            "\n",
            "Epoch 99: val_loss improved from 0.44656 to 0.44459, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.4674 - accuracy: 0.8522 - val_loss: 0.4446 - val_accuracy: 0.8662 - 29s/epoch - 41ms/step\n",
            "Epoch 100/125\n",
            "\n",
            "Epoch 100: val_loss did not improve from 0.44459\n",
            "703/703 - 29s - loss: 0.4687 - accuracy: 0.8528 - val_loss: 0.4554 - val_accuracy: 0.8658 - 29s/epoch - 41ms/step\n",
            "Epoch 101/125\n",
            "\n",
            "Epoch 101: val_loss did not improve from 0.44459\n",
            "703/703 - 29s - loss: 0.4632 - accuracy: 0.8546 - val_loss: 0.4547 - val_accuracy: 0.8636 - 29s/epoch - 42ms/step\n",
            "Epoch 102/125\n",
            "\n",
            "Epoch 102: val_loss did not improve from 0.44459\n",
            "703/703 - 30s - loss: 0.4700 - accuracy: 0.8525 - val_loss: 0.4508 - val_accuracy: 0.8674 - 30s/epoch - 42ms/step\n",
            "Epoch 103/125\n",
            "\n",
            "Epoch 103: val_loss did not improve from 0.44459\n",
            "703/703 - 30s - loss: 0.4594 - accuracy: 0.8546 - val_loss: 0.4547 - val_accuracy: 0.8702 - 30s/epoch - 42ms/step\n",
            "Epoch 104/125\n",
            "\n",
            "Epoch 104: val_loss did not improve from 0.44459\n",
            "703/703 - 29s - loss: 0.4653 - accuracy: 0.8535 - val_loss: 0.4530 - val_accuracy: 0.8662 - 29s/epoch - 41ms/step\n",
            "Epoch 105/125\n",
            "\n",
            "Epoch 105: val_loss did not improve from 0.44459\n",
            "703/703 - 30s - loss: 0.4601 - accuracy: 0.8550 - val_loss: 0.4794 - val_accuracy: 0.8628 - 30s/epoch - 42ms/step\n",
            "Epoch 106/125\n",
            "\n",
            "Epoch 106: val_loss did not improve from 0.44459\n",
            "703/703 - 29s - loss: 0.4587 - accuracy: 0.8547 - val_loss: 0.4498 - val_accuracy: 0.8668 - 29s/epoch - 41ms/step\n",
            "Epoch 107/125\n",
            "\n",
            "Epoch 107: val_loss did not improve from 0.44459\n",
            "703/703 - 30s - loss: 0.4539 - accuracy: 0.8556 - val_loss: 0.4544 - val_accuracy: 0.8644 - 30s/epoch - 43ms/step\n",
            "Epoch 108/125\n",
            "\n",
            "Epoch 108: val_loss did not improve from 0.44459\n",
            "703/703 - 29s - loss: 0.4569 - accuracy: 0.8544 - val_loss: 0.4872 - val_accuracy: 0.8592 - 29s/epoch - 41ms/step\n",
            "Epoch 109/125\n",
            "\n",
            "Epoch 109: val_loss improved from 0.44459 to 0.43995, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.4561 - accuracy: 0.8542 - val_loss: 0.4400 - val_accuracy: 0.8708 - 29s/epoch - 41ms/step\n",
            "Epoch 110/125\n",
            "\n",
            "Epoch 110: val_loss did not improve from 0.43995\n",
            "703/703 - 30s - loss: 0.4548 - accuracy: 0.8557 - val_loss: 0.4639 - val_accuracy: 0.8666 - 30s/epoch - 42ms/step\n",
            "Epoch 111/125\n",
            "\n",
            "Epoch 111: val_loss did not improve from 0.43995\n",
            "703/703 - 29s - loss: 0.4534 - accuracy: 0.8562 - val_loss: 0.4464 - val_accuracy: 0.8652 - 29s/epoch - 41ms/step\n",
            "Epoch 112/125\n",
            "\n",
            "Epoch 112: val_loss did not improve from 0.43995\n",
            "703/703 - 30s - loss: 0.4503 - accuracy: 0.8580 - val_loss: 0.4511 - val_accuracy: 0.8674 - 30s/epoch - 42ms/step\n",
            "Epoch 113/125\n",
            "\n",
            "Epoch 113: val_loss did not improve from 0.43995\n",
            "703/703 - 29s - loss: 0.4563 - accuracy: 0.8544 - val_loss: 0.4413 - val_accuracy: 0.8750 - 29s/epoch - 41ms/step\n",
            "Epoch 114/125\n",
            "\n",
            "Epoch 114: val_loss improved from 0.43995 to 0.42753, saving model to model.weights.best.hdf5\n",
            "703/703 - 29s - loss: 0.4483 - accuracy: 0.8570 - val_loss: 0.4275 - val_accuracy: 0.8766 - 29s/epoch - 42ms/step\n",
            "Epoch 115/125\n",
            "\n",
            "Epoch 115: val_loss did not improve from 0.42753\n",
            "703/703 - 29s - loss: 0.4462 - accuracy: 0.8582 - val_loss: 0.4635 - val_accuracy: 0.8674 - 29s/epoch - 41ms/step\n",
            "Epoch 116/125\n",
            "\n",
            "Epoch 116: val_loss did not improve from 0.42753\n",
            "703/703 - 30s - loss: 0.4481 - accuracy: 0.8585 - val_loss: 0.4679 - val_accuracy: 0.8656 - 30s/epoch - 43ms/step\n",
            "Epoch 117/125\n",
            "\n",
            "Epoch 117: val_loss did not improve from 0.42753\n",
            "703/703 - 29s - loss: 0.4485 - accuracy: 0.8598 - val_loss: 0.4337 - val_accuracy: 0.8714 - 29s/epoch - 41ms/step\n",
            "Epoch 118/125\n",
            "\n",
            "Epoch 118: val_loss did not improve from 0.42753\n",
            "703/703 - 29s - loss: 0.4468 - accuracy: 0.8580 - val_loss: 0.4402 - val_accuracy: 0.8728 - 29s/epoch - 41ms/step\n",
            "Epoch 119/125\n",
            "\n",
            "Epoch 119: val_loss did not improve from 0.42753\n",
            "703/703 - 30s - loss: 0.4429 - accuracy: 0.8609 - val_loss: 0.4366 - val_accuracy: 0.8740 - 30s/epoch - 42ms/step\n",
            "Epoch 120/125\n",
            "\n",
            "Epoch 120: val_loss did not improve from 0.42753\n",
            "703/703 - 29s - loss: 0.4458 - accuracy: 0.8595 - val_loss: 0.4351 - val_accuracy: 0.8722 - 29s/epoch - 41ms/step\n",
            "Epoch 121/125\n",
            "\n",
            "Epoch 121: val_loss did not improve from 0.42753\n",
            "703/703 - 31s - loss: 0.4427 - accuracy: 0.8604 - val_loss: 0.4340 - val_accuracy: 0.8724 - 31s/epoch - 44ms/step\n",
            "Epoch 122/125\n",
            "\n",
            "Epoch 122: val_loss did not improve from 0.42753\n",
            "703/703 - 29s - loss: 0.4443 - accuracy: 0.8600 - val_loss: 0.4432 - val_accuracy: 0.8706 - 29s/epoch - 41ms/step\n",
            "Epoch 123/125\n",
            "\n",
            "Epoch 123: val_loss improved from 0.42753 to 0.42355, saving model to model.weights.best.hdf5\n",
            "703/703 - 30s - loss: 0.4414 - accuracy: 0.8627 - val_loss: 0.4235 - val_accuracy: 0.8774 - 30s/epoch - 42ms/step\n",
            "Epoch 124/125\n",
            "\n",
            "Epoch 124: val_loss did not improve from 0.42355\n",
            "703/703 - 29s - loss: 0.4391 - accuracy: 0.8629 - val_loss: 0.4295 - val_accuracy: 0.8732 - 29s/epoch - 41ms/step\n",
            "Epoch 125/125\n",
            "\n",
            "Epoch 125: val_loss did not improve from 0.42355\n",
            "703/703 - 29s - loss: 0.4390 - accuracy: 0.8597 - val_loss: 0.4376 - val_accuracy: 0.8712 - 29s/epoch - 41ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Evaluate"
      ],
      "metadata": {
        "id": "QVtTe9yvumMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('model.weights.best.hdf5')"
      ],
      "metadata": {
        "id": "JO9D4gEuuji7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy: %.2f%%' % (score[1]*100))"
      ],
      "metadata": {
        "id": "TGHVzuVvuCW3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "200e671a-eddb-40bf-db5b-e607127cc9ac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 86.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot learning curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(hist.history['accuracy'], label='train')\n",
        "plt.plot(hist.history['val_accuracy'], label='validation')"
      ],
      "metadata": {
        "id": "3Gb-MwFhu9Ni",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "a4aae5a0-527d-47f4-92c4-81bca60975e1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7e95fc0d5630>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}